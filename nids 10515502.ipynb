{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msi0P_wiAdEr"
   },
   "source": [
    "###Import standard Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "yke-9DZnAcEg",
    "outputId": "26f63967-c69f-47f2-e145-221e016bda65"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f6018151ae77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVarianceThreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "import csv\n",
    "import io\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import operator\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(sys.version)\n",
    "print(sklearn.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7H2Z1BYA4ox"
   },
   "source": [
    "### Load the Dataset\n",
    "\n",
    "###  KDDTrain+_2.csv & KDDTest+_2.csv are the training and test datasets with the last column of difficulty score removed already\n",
    "\n",
    "### Load dataset from local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "0vzRlpW9A5AK",
    "outputId": "1e2463d9-104c-44f1-83a4-568a303dd679"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7i42U-vC15u"
   },
   "source": [
    "### assign column names to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1253xRxC2fp"
   },
   "outputs": [],
   "source": [
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(io.BytesIO(uploaded['KDDTrain+_2.csv']), header=None, names = col_names)\n",
    "df_test = pd.read_csv(io.BytesIO(uploaded['KDDTest+_2.csv']), header=None, names = col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4EmJDlGDKw0"
   },
   "source": [
    "### shape function gives the dimensions of the dataset\n",
    "\n",
    "### View the first five rows of the training dataset\n",
    "\n",
    "### View the Statistical Summary\n",
    "\n",
    "### View the Label Distribution of Training and Test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1190
    },
    "colab_type": "code",
    "id": "D3aQuhMiDLN_",
    "outputId": "27c4ae49-723a-4050-9d38-608f944f8825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "('Dimensions of the Training set:', (125973, 42))\n",
      "('Dimensions of the Test set:', (22544, 42))\n",
      "Label distribution Training set:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "()\n",
      "Label distribution Test set:\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "udpstorm              2\n",
      "sqlattack             2\n",
      "perl                  2\n",
      "loadmodule            2\n",
      "phf                   2\n",
      "worm                  2\n",
      "imap                  1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(type(df_test))\n",
    "\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)\n",
    "\n",
    "df.head(10)\n",
    "df.describe()\n",
    "\n",
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4A2P3ifBDyHW"
   },
   "source": [
    "### Step 1: Data preprocessing:\n",
    "\n",
    "#### One-Hot-Encoding (one-of-K) is used to to transform all categorical features into binary features. \n",
    "\n",
    "#### Requirement for One-Hot-encoding:\n",
    "\n",
    "\"The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) features. The output will be a sparse matrix where each column corresponds to one possible value of one feature. It is assumed that input features take on values in the range [0, n_values).\"\n",
    " \n",
    "Therefore the features first need to be transformed with LabelEncoder, to transform every category to a number.\n",
    "\n",
    "\n",
    "### Identify categorical features\n",
    "\n",
    "columns that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n",
    "\n",
    "### explore categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OaICubY_Dypy",
    "outputId": "8d5fc96b-3ce9-42a2-b7d0-16a6890ec867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 70 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 23 categories\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLZAyAnwEdC3"
   },
   "source": [
    "### see how distributed the feature service is.\n",
    "### Since it is evenly distributed and therefore we need to make dummies for all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Lkrm4gntEeeS",
    "outputId": "cd8516d7-364d-49ad-e3be-7a7ac35071ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "Distribution of categories in service:\n",
      "http        40338\n",
      "private     21853\n",
      "domain_u     9043\n",
      "smtp         7313\n",
      "ftp_data     6860\n",
      "Name: service, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['service'].value_counts().sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pc8svzCGEpX2"
   },
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "FGhVCFVPEtE2",
    "outputId": "2f87569f-33ef-45ae-d77e-b25b7e2be861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 64 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 38 categories\n"
     ]
    }
   ],
   "source": [
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-mABGIwE3_k"
   },
   "source": [
    "\n",
    "### Need to make dummies for all categories as the distribution is fairly even. In total: 3+70+11=84 dummies.\n",
    "\n",
    "### Comparing the results shows that the Test set has fewer categories (6), these need to be added as empty columns.\n",
    "\n",
    "### LabelEncoder\n",
    "\n",
    "### Insert categorical features into a 2D numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "3rpb31oJFFIH",
    "outputId": "0c0a0797-9f47-4432-df30-5921840c245d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type   service flag\n",
       "0           tcp  ftp_data   SF\n",
       "1           udp     other   SF\n",
       "2           tcp   private   S0\n",
       "3           tcp      http   SF\n",
       "4           tcp      http   SF"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['protocol_type', 'service', 'flag']\n",
    "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
    "categorical_columns=['protocol_type', 'service', 'flag'] \n",
    " # Get the categorical values into a 2D numpy array\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "df_categorical_values.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YONjpYOvFe9e"
   },
   "source": [
    "Make column names for dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zM448Ex7Fg5C",
    "outputId": "2ca44b85-3d90-42d4-d0bb-c1380190b5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
     ]
    }
   ],
   "source": [
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "# put together\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "print(dumcols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD3mO_dWLp5Y"
   },
   "source": [
    "###  MADE 84 DUMMIES for categoricals in training dataset\n",
    "\n",
    "### repeat the same process for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPJYex00Lr_g"
   },
   "outputs": [],
   "source": [
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "85K3G5OaL0ZJ"
   },
   "source": [
    "### Transform categorical features into numbers using LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "hhuOIc4aL7tA",
    "outputId": "b0a5019b-cd63-4e26-cebe-e586cf594cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n"
     ]
    }
   ],
   "source": [
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_categorical_values_enc.head())\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6hGchT_MDhP"
   },
   "source": [
    "### One-Hot-Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "Imsb0fdYMCxn",
    "outputId": "a27f0eb9-c568-4726-87fb-094e7968fdf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol_type_icmp</th>\n",
       "      <th>Protocol_type_tcp</th>\n",
       "      <th>Protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>service_courier</th>\n",
       "      <th>service_csnet_ns</th>\n",
       "      <th>service_ctf</th>\n",
       "      <th>service_daytime</th>\n",
       "      <th>service_discard</th>\n",
       "      <th>service_domain</th>\n",
       "      <th>service_domain_u</th>\n",
       "      <th>service_echo</th>\n",
       "      <th>service_eco_i</th>\n",
       "      <th>service_ecr_i</th>\n",
       "      <th>service_efs</th>\n",
       "      <th>service_exec</th>\n",
       "      <th>service_finger</th>\n",
       "      <th>service_ftp</th>\n",
       "      <th>service_ftp_data</th>\n",
       "      <th>service_gopher</th>\n",
       "      <th>service_harvest</th>\n",
       "      <th>service_hostnames</th>\n",
       "      <th>service_http</th>\n",
       "      <th>service_http_2784</th>\n",
       "      <th>service_http_443</th>\n",
       "      <th>service_http_8001</th>\n",
       "      <th>service_imap4</th>\n",
       "      <th>service_iso_tsap</th>\n",
       "      <th>service_klogin</th>\n",
       "      <th>service_kshell</th>\n",
       "      <th>service_ldap</th>\n",
       "      <th>service_link</th>\n",
       "      <th>service_login</th>\n",
       "      <th>service_mtp</th>\n",
       "      <th>service_name</th>\n",
       "      <th>...</th>\n",
       "      <th>service_nnsp</th>\n",
       "      <th>service_nntp</th>\n",
       "      <th>service_ntp_u</th>\n",
       "      <th>service_other</th>\n",
       "      <th>service_pm_dump</th>\n",
       "      <th>service_pop_2</th>\n",
       "      <th>service_pop_3</th>\n",
       "      <th>service_printer</th>\n",
       "      <th>service_private</th>\n",
       "      <th>service_red_i</th>\n",
       "      <th>service_remote_job</th>\n",
       "      <th>service_rje</th>\n",
       "      <th>service_shell</th>\n",
       "      <th>service_smtp</th>\n",
       "      <th>service_sql_net</th>\n",
       "      <th>service_ssh</th>\n",
       "      <th>service_sunrpc</th>\n",
       "      <th>service_supdup</th>\n",
       "      <th>service_systat</th>\n",
       "      <th>service_telnet</th>\n",
       "      <th>service_tftp_u</th>\n",
       "      <th>service_tim_i</th>\n",
       "      <th>service_time</th>\n",
       "      <th>service_urh_i</th>\n",
       "      <th>service_urp_i</th>\n",
       "      <th>service_uucp</th>\n",
       "      <th>service_uucp_path</th>\n",
       "      <th>service_vmnet</th>\n",
       "      <th>service_whois</th>\n",
       "      <th>flag_OTH</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol_type_icmp  Protocol_type_tcp  ...  flag_SF  flag_SH\n",
       "0                 0.0                1.0  ...      1.0      0.0\n",
       "1                 0.0                0.0  ...      1.0      0.0\n",
       "2                 0.0                1.0  ...      0.0      0.0\n",
       "3                 0.0                1.0  ...      1.0      0.0\n",
       "4                 0.0                1.0  ...      1.0      0.0\n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zc_aw2vBMWYO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dMO57KhzMa25",
    "outputId": "4bfbc2e4-51c2-4481-dcf5-1749a202d7f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 84)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainservice=df['service'].tolist()\n",
    "testservice= df_test['service'].tolist()\n",
    "difference=list(set(trainservice) - set(testservice))\n",
    "string = 'service_'\n",
    "difference=[string + x for x in difference]\n",
    "difference\n",
    "\n",
    "for col in difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "testdf_cat_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcToGXhTMiVM"
   },
   "source": [
    "### Join encoded categorical dataframe with the non-categorical dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YC54SI0JMjwy",
    "outputId": "32f3d45b-2965-4da4-d223-33444c8d3c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 123)\n",
      "(22544, 123)\n"
     ]
    }
   ],
   "source": [
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kO0kNbUGM3Am"
   },
   "source": [
    "### We have now Obtained 123 features -- Previous 42 Features + Current Encoded 84 Features - 3 features (flag, protocol, service)\n",
    "\n",
    "\n",
    "### Split Dataset into 4 subsets for every attack category\n",
    "\n",
    "### Rename every attack label: 0=normal, 1=DoS, 2=Probe, 3=R2L and 4=U2R.\n",
    "### Replace labels column with new labels column\n",
    "### Make new subsets\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "eOwV7emwNL9k",
    "outputId": "ea5f2af4-adba-47c1-a073-7ff90f2384e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# take label column\n",
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "# change the label column\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "# put the new label column back\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "print(newdf['label'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "3oW3DoK2NUEs",
    "outputId": "b4ce2a3b-5a28-4f4d-cad1-b50ddc4b3fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "('Dimensions of DoS:', (113270, 123))\n",
      "('Dimensions of Probe:', (78999, 123))\n",
      "('Dimensions of R2L:', (68338, 123))\n",
      "('Dimensions of U2R:', (67395, 123))\n",
      "Test:\n",
      "('Dimensions of DoS:', (17171, 123))\n",
      "('Dimensions of Probe:', (12132, 123))\n",
      "('Dimensions of R2L:', (12596, 123))\n",
      "('Dimensions of U2R:', (9778, 123))\n"
     ]
    }
   ],
   "source": [
    "to_drop_DoS = [2,3,4]\n",
    "to_drop_Probe = [1,3,4]\n",
    "to_drop_R2L = [1,2,4]\n",
    "to_drop_U2R = [1,2,3]\n",
    "DoS_df=newdf[~newdf['label'].isin(to_drop_DoS)];\n",
    "Probe_df=newdf[~newdf['label'].isin(to_drop_Probe)];\n",
    "R2L_df=newdf[~newdf['label'].isin(to_drop_R2L)];\n",
    "U2R_df=newdf[~newdf['label'].isin(to_drop_U2R)];\n",
    "\n",
    "#test\n",
    "DoS_df_test=newdf_test[~newdf_test['label'].isin(to_drop_DoS)];\n",
    "Probe_df_test=newdf_test[~newdf_test['label'].isin(to_drop_Probe)];\n",
    "R2L_df_test=newdf_test[~newdf_test['label'].isin(to_drop_R2L)];\n",
    "U2R_df_test=newdf_test[~newdf_test['label'].isin(to_drop_U2R)];\n",
    "print('Train:')\n",
    "print('Dimensions of DoS:' ,DoS_df.shape)\n",
    "print('Dimensions of Probe:' ,Probe_df.shape)\n",
    "print('Dimensions of R2L:' ,R2L_df.shape)\n",
    "print('Dimensions of U2R:' ,U2R_df.shape)\n",
    "print('Test:')\n",
    "print('Dimensions of DoS:' ,DoS_df_test.shape)\n",
    "print('Dimensions of Probe:' ,Probe_df_test.shape)\n",
    "print('Dimensions of R2L:' ,R2L_df_test.shape)\n",
    "print('Dimensions of U2R:' ,U2R_df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGlgat4UNfPX"
   },
   "source": [
    "###Step 2: Feature Scaling:\n",
    "\n",
    "\n",
    "\n",
    "Split dataframes into X & Y\n",
    "assign X as a dataframe of feautures and Y as a series of outcome variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXy91ktUNiip"
   },
   "outputs": [],
   "source": [
    "X_DoS = DoS_df.drop('label',1)\n",
    "Y_DoS = DoS_df.label\n",
    "X_Probe = Probe_df.drop('label',1)\n",
    "Y_Probe = Probe_df.label\n",
    "X_R2L = R2L_df.drop('label',1)\n",
    "Y_R2L = R2L_df.label\n",
    "X_U2R = U2R_df.drop('label',1)\n",
    "Y_U2R = U2R_df.label\n",
    "# test set\n",
    "X_DoS_test = DoS_df_test.drop('label',1)\n",
    "Y_DoS_test = DoS_df_test.label\n",
    "X_Probe_test = Probe_df_test.drop('label',1)\n",
    "Y_Probe_test = Probe_df_test.label\n",
    "X_R2L_test = R2L_df_test.drop('label',1)\n",
    "Y_R2L_test = R2L_df_test.label\n",
    "X_U2R_test = U2R_df_test.drop('label',1)\n",
    "Y_U2R_test = U2R_df_test.label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjN8GwW6NpOx"
   },
   "source": [
    "### Save a list of feature names for later use (it is the same for every attack category). \n",
    "\n",
    "### Column names are dropped at this stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApsniowRNsi_"
   },
   "outputs": [],
   "source": [
    "colNames=list(X_DoS)\n",
    "colNames_test=list(X_DoS_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSWp6E-bNvu7"
   },
   "source": [
    "### Use StandardScaler() to scale the dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "L-qpD8u2N0iB",
    "outputId": "ff271c9c-812c-423a-8329-6feb141e44ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:18: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_DoS)\n",
    "X_DoS=scaler1.transform(X_DoS) \n",
    "scaler2 = preprocessing.StandardScaler().fit(X_Probe)\n",
    "X_Probe=scaler2.transform(X_Probe) \n",
    "scaler3 = preprocessing.StandardScaler().fit(X_R2L)\n",
    "X_R2L=scaler3.transform(X_R2L) \n",
    "scaler4 = preprocessing.StandardScaler().fit(X_U2R)\n",
    "X_U2R=scaler4.transform(X_U2R) \n",
    "# test data\n",
    "scaler5 = preprocessing.StandardScaler().fit(X_DoS_test)\n",
    "X_DoS_test=scaler5.transform(X_DoS_test) \n",
    "scaler6 = preprocessing.StandardScaler().fit(X_Probe_test)\n",
    "X_Probe_test=scaler6.transform(X_Probe_test) \n",
    "scaler7 = preprocessing.StandardScaler().fit(X_R2L_test)\n",
    "X_R2L_test=scaler7.transform(X_R2L_test) \n",
    "scaler8 = preprocessing.StandardScaler().fit(X_U2R_test)\n",
    "X_U2R_test=scaler8.transform(X_U2R_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lLr9_j-OADU"
   },
   "outputs": [],
   "source": [
    "#Scale a single column into range\n",
    "#X_dos_test_instance=X_DoS_test.iloc[4,:].values\n",
    "#X_dos_test_instance=(X_dos_test_instance - np.mean(X_dos_test_instance)) / np.std(X_dos_test_instance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaAKnnKGOJSi"
   },
   "source": [
    "### Check that the Standard Deviation is 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "fUVlGLQ7OJwW",
    "outputId": "7e3ad3f5-7ff7-4598-b787-fadc135bb093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_DoS.std(axis=0))\n",
    "\n",
    "X_Probe.std(axis=0);\n",
    "X_R2L.std(axis=0);\n",
    "X_U2R.std(axis=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aiSi8_9OaF4"
   },
   "source": [
    "\n",
    "### Univariate Feature Selection using ANOVA F-test\n",
    "\n",
    "### univariate feature selection with ANOVA F-test. using secondPercentile method, then RFE\n",
    "\n",
    "### Scikit-learn exposes feature selection routines as objects that implement the transform method\n",
    "\n",
    "### SelectPercentile: removes all but a user-specified highest scoring percentage of features\n",
    "\n",
    "### f_classif: ANOVA F-value between label/feature for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "iv-3KB0xOc1_",
    "outputId": "230925bd-081c-4eef-85c9-ae6a36dab05b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 16  44  63  66  68  86 114] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 4 16] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [  4  16  43  44  46  47  48  49  50  51  54  57  58  62  63  64  66  67\n",
      "  68  70  71  72  73  74  76  77  78  79  80  81  82  83  86  87  89  92\n",
      "  93  96  98  99 100 107 108 109 110 114] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features selected for DoS:', ['logged_in', 'count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'service_http', 'flag_S0', 'flag_SF'])\n",
      "()\n",
      "('Features selected for Probe:', ['logged_in', 'rerror_rate', 'srv_rerror_rate', 'dst_host_srv_count', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'Protocol_type_icmp', 'service_eco_i', 'service_private', 'flag_SF'])\n",
      "()\n",
      "('Features selected for R2L:', ['src_bytes', 'dst_bytes', 'hot', 'num_failed_logins', 'is_guest_login', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp', 'service_ftp_data', 'service_http', 'service_imap4', 'flag_RSTO'])\n",
      "()\n",
      "('Features selected for U2R:', ['urgent', 'hot', 'root_shell', 'num_file_creations', 'num_shells', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp_data', 'service_http', 'service_telnet'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [  4  16  43  44  46  47  48  49  50  51  54  57  58  62  63  64  66  67\n",
      "  68  70  71  72  73  74  75  76  77  78  79  80  81  82  83  86  87  89\n",
      "  92  93  96  98  99 100 107 108 109 110 114] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "np.seterr(divide='ignore', invalid='ignore');\n",
    "selector=SelectPercentile(f_classif, percentile=10)\n",
    "X_newDoS = selector.fit_transform(X_DoS,Y_DoS)\n",
    "X_newDoS.shape\n",
    "# ### Get the features that were selected: DoS\n",
    "true=selector.get_support()\n",
    "newcolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "newcolname_DoS=list( colNames[i] for i in newcolindex_DoS )\n",
    "newcolname_DoS\n",
    "X_newProbe = selector.fit_transform(X_Probe,Y_Probe)\n",
    "X_newProbe.shape\n",
    "# ### Get the features that were selected: Probe\n",
    "true=selector.get_support()\n",
    "newcolindex_Probe=[i for i, x in enumerate(true) if x]\n",
    "newcolname_Probe=list( colNames[i] for i in newcolindex_Probe )\n",
    "newcolname_Probe\n",
    "X_newR2L = selector.fit_transform(X_R2L,Y_R2L)\n",
    "X_newR2L.shape\n",
    "# ### Get the features that were selected: R2L\n",
    "true=selector.get_support()\n",
    "newcolindex_R2L=[i for i, x in enumerate(true) if x]\n",
    "newcolname_R2L=list( colNames[i] for i in newcolindex_R2L)\n",
    "newcolname_R2L\n",
    "X_newU2R = selector.fit_transform(X_U2R,Y_U2R)\n",
    "X_newU2R.shape\n",
    "# ### Get the features that were selected: U2R\n",
    "true=selector.get_support()\n",
    "newcolindex_U2R=[i for i, x in enumerate(true) if x]\n",
    "newcolname_U2R=list( colNames[i] for i in newcolindex_U2R)\n",
    "newcolname_U2R\n",
    "# # Summary of features selected by Univariate Feature Selection\n",
    "print('Features selected for DoS:',newcolname_DoS)\n",
    "print()\n",
    "print('Features selected for Probe:',newcolname_Probe)\n",
    "print()\n",
    "print('Features selected for R2L:',newcolname_R2L)\n",
    "print()\n",
    "print('Features selected for U2R:',newcolname_U2R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tp72_5wrO2pn"
   },
   "source": [
    "The authors state that \"After obtaining the adequate number of features during the univariate selection process, a recursive feature elimination (RFE) was operated with the number of features passed as parameter to identify the features selected\". \n",
    "\n",
    "This either implies that RFE is only used for obtaining the features previously selected but also obtaining the rank. This use of RFE is however very redundant as the features selected can be obtained in another way (Done in this project). \n",
    "\n",
    "One can also not say that the features were selected by RFE, as it was not used for this. The quote could however also imply that only the number 13 from univariate feature selection was used. RFE is then used for feature selection trying to find the best 13 features. \n",
    "\n",
    "With this use of RFE one can actually say that it was used for feature selection. However the authors obtained different numbers of features for every attack category, 12 for DoS, 15 for Probe, 13 for R2L and 11 for U2R. This concludes that it is not clear what mechanism is used for feature selection. \n",
    " \n",
    "From now on the number of features for every attack category is 13.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "r8xEs-9hO2Jb",
    "outputId": "fd122206-3401-456e-9fbf-edf3e5ce4f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoS Features sorted by their rank:\n",
      "[(1.0, 'count'), (2.0, 'flag_SF'), (3.0, 'same_srv_rate'), (4.0, 'dst_host_srv_serror_rate'), (5.0, 'dst_host_serror_rate'), (6.0, 'serror_rate'), (7.0, 'dst_host_same_srv_rate'), (8.0, 'dst_host_srv_count'), (9.0, 'dst_host_count'), (10.0, 'logged_in'), (11.0, 'flag_S0'), (12.0, 'service_http'), (13.0, 'srv_serror_rate')]\n",
      "Probe Features sorted by their rank:\n",
      "[(1.0, 'dst_host_srv_count'), (2.0, 'dst_host_srv_diff_host_rate'), (3.0, 'dst_host_srv_rerror_rate'), (4.0, 'dst_host_diff_srv_rate'), (5.0, 'service_private'), (6.0, 'Protocol_type_icmp'), (7.0, 'dst_host_same_src_port_rate'), (8.0, 'service_eco_i'), (9.0, 'dst_host_rerror_rate'), (10.0, 'flag_SF'), (11.0, 'logged_in'), (12.0, 'rerror_rate'), (13.0, 'srv_rerror_rate')]\n",
      "R2L Features sorted by their rank:\n",
      "[(1.0, 'src_bytes'), (2.0, 'hot'), (3.0, 'dst_bytes'), (4.0, 'dst_host_srv_diff_host_rate'), (5.0, 'dst_host_srv_count'), (6.0, 'dst_host_same_src_port_rate'), (7.0, 'service_ftp_data'), (8.0, 'is_guest_login'), (9.0, 'num_failed_logins'), (10.0, 'service_http'), (11.0, 'service_imap4'), (12.0, 'flag_RSTO'), (13.0, 'service_ftp')]\n",
      "U2R Features sorted by their rank:\n",
      "[(1.0, 'hot'), (2.0, 'dst_host_srv_count'), (3.0, 'dst_host_count'), (4.0, 'root_shell'), (5.0, 'num_file_creations'), (6.0, 'dst_host_same_src_port_rate'), (7.0, 'dst_host_srv_diff_host_rate'), (8.0, 'service_telnet'), (9.0, 'service_ftp_data'), (10.0, 'num_shells'), (11.0, 'service_http'), (12.0, 'urgent'), (13.0, 'srv_diff_host_rate')]\n",
      "[False  True  True False  True False False False False False False False\n",
      " False False False False False False False  True  True False False False\n",
      " False  True  True False False False False False  True False  True  True\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False]\n",
      "('true is ', array([False,  True,  True, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False,  True, False, False, False, False, False, False, False,\n",
      "       False, False,  True,  True,  True,  True,  True, False, False,\n",
      "        True,  True, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False,  True, False, False, False, False, False, False, False,\n",
      "       False, False,  True, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "        True, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False]))\n",
      "('Features selected for DoS:', ['src_bytes', 'dst_bytes', 'wrong_fragment', 'count', 'srv_count', 'same_srv_rate', 'diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'Protocol_type_icmp', 'service_ecr_i', 'flag_SF'])\n",
      "()\n",
      "('Features selected for Probe:', ['src_bytes', 'dst_bytes', 'count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'service_eco_i', 'service_http', 'service_private'])\n",
      "()\n",
      "('Features selected for R2L:', ['duration', 'src_bytes', 'dst_bytes', 'hot', 'is_guest_login', 'srv_count', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate', 'service_ftp_data'])\n",
      "()\n",
      "('Features selected for U2R:', ['duration', 'src_bytes', 'dst_bytes', 'hot', 'root_shell', 'num_file_creations', 'count', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate'])\n",
      "(113270, 13)\n",
      "(78999, 13)\n",
      "(68338, 13)\n",
      "(67395, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a decision tree classifier. By convention, clf means 'classifier'\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(clf, n_features_to_select=1)\n",
    "Y_DoS=Y_DoS.astype('int')\n",
    "rfe.fit(X_newDoS, Y_DoS)\n",
    "print (\"DoS Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_DoS)))\n",
    "Y_Probe=Y_Probe.astype('int')\n",
    "rfe.fit(X_newProbe, Y_Probe)\n",
    "print (\"Probe Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_Probe)))\n",
    "Y_R2L=Y_R2L.astype('int')\n",
    "rfe.fit(X_newR2L, Y_R2L)\n",
    " \n",
    "print (\"R2L Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_R2L)))\n",
    "Y_U2R=Y_U2R.astype('int')\n",
    "rfe.fit(X_newU2R, Y_U2R)\n",
    " \n",
    "print (\"U2R Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_U2R)))\n",
    "# # 2. Recursive Feature Elimination, select 13 features each of 122 (Option 2: get 13 best features from 122 from RFE)\n",
    "from sklearn.feature_selection import RFE\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "rfe = RFE(estimator=clf, n_features_to_select=13, step=1)\n",
    "rfe.fit(X_DoS, Y_DoS)\n",
    "X_rfeDoS=rfe.transform(X_DoS)\n",
    "true=rfe.support_\n",
    "rfecolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_DoS=list(colNames[i] for i in rfecolindex_DoS)\n",
    "print(true)\n",
    "rfe.fit(X_Probe, Y_Probe)\n",
    "X_rfeProbe=rfe.transform(X_Probe)\n",
    "true=rfe.support_\n",
    "print(\"true is \",true)\n",
    "rfecolindex_Probe=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_Probe=list(colNames[i] for i in rfecolindex_Probe)\n",
    "rfe.fit(X_R2L, Y_R2L)\n",
    "X_rfeR2L=rfe.transform(X_R2L)\n",
    "true=rfe.support_\n",
    "rfecolindex_R2L=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_R2L=list(colNames[i] for i in rfecolindex_R2L)\n",
    "rfe.fit(X_U2R, Y_U2R)\n",
    "X_rfeU2R=rfe.transform(X_U2R)\n",
    "true=rfe.support_\n",
    "rfecolindex_U2R=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_U2R=list(colNames[i] for i in rfecolindex_U2R)\n",
    "# # Summary of features selected by RFE\n",
    "print('Features selected for DoS:',rfecolname_DoS)\n",
    "print()\n",
    "print('Features selected for Probe:',rfecolname_Probe)\n",
    "print()\n",
    "print('Features selected for R2L:',rfecolname_R2L)\n",
    "print()\n",
    "print('Features selected for U2R:',rfecolname_U2R)\n",
    "print(X_rfeDoS.shape)\n",
    "print(X_rfeProbe.shape)\n",
    "print(X_rfeR2L.shape)\n",
    "print(X_rfeU2R.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0FXy929Tww_"
   },
   "source": [
    "### Step 4: Build the model:\n",
    "\n",
    "#### Classifier is trained for all features and for reduced features, for later comparison.\n",
    "\n",
    "#### The classifier model itself is stored in the clf variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2094
    },
    "colab_type": "code",
    "id": "xr0PV8ghT8Zl",
    "outputId": "59c0787e-9d22-4a8b-95ee-6f6053fcbfc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 21:29:11.995414 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0103 21:29:12.013663 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0103 21:29:12.032066 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0103 21:29:12.069962 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0103 21:29:12.092797 139948698924928 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0103 21:29:12.197354 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0103 21:29:12.226160 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0103 21:29:12.236444 139948698924928 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 122)               15006     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 366)               45018     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 366)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                22020     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 82,105\n",
      "Trainable params: 82,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 21:29:12.676765 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0103 21:29:12.800867 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W0103 21:29:12.916357 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0103 21:29:12.928936 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0103 21:29:12.930927 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0103 21:29:13.072496 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0103 21:29:13.074076 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 21:29:13.223594 139948698924928 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56635/56635 [==============================] - 15s 273us/step - loss: 0.2086 - acc: 0.9873\n",
      "Epoch 2/10\n",
      "56635/56635 [==============================] - 15s 264us/step - loss: 0.0929 - acc: 0.9879\n",
      "Epoch 3/10\n",
      "56635/56635 [==============================] - 15s 260us/step - loss: 0.0823 - acc: 0.9889\n",
      "Epoch 4/10\n",
      "56635/56635 [==============================] - 15s 264us/step - loss: 0.0770 - acc: 0.9897\n",
      "Epoch 5/10\n",
      "56635/56635 [==============================] - 15s 259us/step - loss: 0.0722 - acc: 0.9905\n",
      "Epoch 6/10\n",
      "56635/56635 [==============================] - 15s 262us/step - loss: 0.0698 - acc: 0.9908\n",
      "Epoch 7/10\n",
      "56635/56635 [==============================] - 15s 261us/step - loss: 0.0690 - acc: 0.9910\n",
      "Epoch 8/10\n",
      "56635/56635 [==============================] - 15s 266us/step - loss: 0.0660 - acc: 0.9914\n",
      "Epoch 9/10\n",
      "56635/56635 [==============================] - 15s 257us/step - loss: 0.0651 - acc: 0.9914\n",
      "Epoch 10/10\n",
      "56635/56635 [==============================] - 15s 259us/step - loss: 0.0651 - acc: 0.9915\n",
      "56635/56635 [==============================] - 5s 86us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 122)               15006     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 366)               45018     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 366)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                22020     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 82,105\n",
      "Trainable params: 82,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "56635/56635 [==============================] - 15s 270us/step - loss: 0.2036 - acc: 0.9864\n",
      "Epoch 2/10\n",
      "56635/56635 [==============================] - 15s 267us/step - loss: 0.0914 - acc: 0.9879\n",
      "Epoch 3/10\n",
      "56635/56635 [==============================] - 16s 279us/step - loss: 0.0822 - acc: 0.9894\n",
      "Epoch 4/10\n",
      "56635/56635 [==============================] - 15s 267us/step - loss: 0.0760 - acc: 0.9907\n",
      "Epoch 5/10\n",
      "56635/56635 [==============================] - 15s 262us/step - loss: 0.0726 - acc: 0.9905\n",
      "Epoch 6/10\n",
      "56635/56635 [==============================] - 15s 264us/step - loss: 0.0711 - acc: 0.9911\n",
      "Epoch 7/10\n",
      "56635/56635 [==============================] - 15s 264us/step - loss: 0.0677 - acc: 0.9912\n",
      "Epoch 8/10\n",
      "56635/56635 [==============================] - 15s 267us/step - loss: 0.0674 - acc: 0.9913\n",
      "Epoch 9/10\n",
      "56635/56635 [==============================] - 15s 262us/step - loss: 0.0650 - acc: 0.9919\n",
      "Epoch 10/10\n",
      "56635/56635 [==============================] - 15s 263us/step - loss: 0.0652 - acc: 0.9918\n",
      "56635/56635 [==============================] - 5s 83us/step\n",
      "('Mean Cross Validated accuracy', 0.9918954692083075)\n"
     ]
    }
   ],
   "source": [
    "def create_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(122,activation='relu',input_shape=(122,),kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(366,activation='relu',kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(60,activation='relu',kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "classifier = KerasClassifier(build_fn=create_network, epochs=10, batch_size=10, verbose=1)\n",
    "accuracies=cross_val_score(estimator=classifier, X=X_DoS, y=Y_DoS, cv=2)\n",
    "print(\"Mean Cross Validated accuracy\",np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jfngX92UTS_"
   },
   "source": [
    "### Step 5: Prediction & Evaluation (validation):\n",
    "Make Prediction for a Single vector -- From the daataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFKlbMy8UWSO"
   },
   "outputs": [],
   "source": [
    "def testing(i,model_dos,model_probe,model_r2l,model_u2r):\n",
    "    #global test_instance\n",
    "    test_instance=df_test.iloc[i,:].values\n",
    "    print(\"----Making Prediction for Input--------\")\n",
    "    print(test_instance)\n",
    "    test_instance=pd.Series(test_instance,index=col_names)\n",
    "    final_df=df_test.append(test_instance,ignore_index=True)\n",
    "    \n",
    "    categorical_columns=['protocol_type', 'service', 'flag'] \n",
    "     # Get the categorical values into a 2D numpy array\n",
    "   \n",
    "    testdf_categorical_values =final_df[categorical_columns]\n",
    "    testdf_categorical_values.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "    unique_service_test=sorted(final_df.service.unique())\n",
    "    unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "    testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n",
    "    \n",
    "    testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    # test set\n",
    "    testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "    testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "    \n",
    "    for col in difference:\n",
    "        testdf_cat_data[col] = 0\n",
    "\n",
    "    testdf_cat_data.shape\n",
    "    \n",
    "    newdf_test_instance=final_df.join(testdf_cat_data)\n",
    "    newdf_test_instance.drop('flag', axis=1, inplace=True)\n",
    "    newdf_test_instance.drop('protocol_type', axis=1, inplace=True)\n",
    "    newdf_test_instance.drop('service', axis=1, inplace=True)\n",
    "    \n",
    "    newdf_test_instance['label'] = newlabeldf_test\n",
    "    \n",
    "    newdf_test_instance=newdf_test_instance.drop('label',1)\n",
    "\n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "    scaler = preprocessing.StandardScaler().fit(newdf_test_instance)\n",
    "    newdf_test_instance=scaler.transform(newdf_test_instance) \n",
    "    \n",
    "    \n",
    "    test_vec=newdf_test_instance[-1,:].reshape(1,122)\n",
    "    y_pred_dos=model_dos.predict(test_vec)\n",
    "    y_pred_probe=model_probe.predict(test_vec)\n",
    "    y_pred_u2r=model_u2r.predict(test_vec)\n",
    "    y_pred_r2l=model_r2l.predict(test_vec)\n",
    "    \n",
    "    print(\"|  ----DOS ---- | --- Probe ---- | ---- R2L ---- | ----U2R ---- | \")\n",
    "    print(y_pred_dos,y_pred_probe,y_pred_r2l,y_pred_u2r)\n",
    "    \n",
    "    \n",
    "    return newdf_test_instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eax4GYQxZzOI"
   },
   "source": [
    "#### Evaluate using the loaded model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "iUkvJWMueGb3",
    "outputId": "2a56f0e0-0c68-48fc-d7fa-90d3aa0b0f16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-dba998e4-d0f9-462b-bf33-3d359563a570\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-dba998e4-d0f9-462b-bf33-3d359563a570\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model_dos.h5 to model_dos (1).h5\n",
      "Saving model_dos.json to model_dos (1).json\n",
      "Saving model_probe.h5 to model_probe.h5\n",
      "Saving model_probe.json to model_probe (1).json\n",
      "Saving model_r2l.h5 to model_r2l.h5\n",
      "Saving model_r2l.json to model_r2l (1).json\n",
      "Saving model_u2r.h5 to model_u2r.h5\n",
      "Saving model_u2r.json to model_u2r (1).json\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "\n",
    "json_file = open('model_dos.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_dos = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_dos.load_weights(\"model_dos.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "json_file = open('model_probe.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_probe = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_probe.load_weights(\"model_probe.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "json_file = open('model_u2r.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_u2r = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_u2r.load_weights(\"model_u2r.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "json_file = open('model_r2l.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_r2l = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_r2l.load_weights(\"model_r2l.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "tb5jYBnBfn57",
    "outputId": "ff365e83-9b2f-43f4-eb29-63ac746056ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'duration', u'protocol_type', u'service', u'flag', u'src_bytes',\n",
      "       u'dst_bytes', u'land', u'wrong_fragment', u'urgent', u'hot',\n",
      "       u'num_failed_logins', u'logged_in', u'num_compromised', u'root_shell',\n",
      "       u'su_attempted', u'num_root', u'num_file_creations', u'num_shells',\n",
      "       u'num_access_files', u'num_outbound_cmds', u'is_host_login',\n",
      "       u'is_guest_login', u'count', u'srv_count', u'serror_rate',\n",
      "       u'srv_serror_rate', u'rerror_rate', u'srv_rerror_rate',\n",
      "       u'same_srv_rate', u'diff_srv_rate', u'srv_diff_host_rate',\n",
      "       u'dst_host_count', u'dst_host_srv_count', u'dst_host_same_srv_rate',\n",
      "       u'dst_host_diff_srv_rate', u'dst_host_same_src_port_rate',\n",
      "       u'dst_host_srv_diff_host_rate', u'dst_host_serror_rate',\n",
      "       u'dst_host_srv_serror_rate', u'dst_host_rerror_rate',\n",
      "       u'dst_host_srv_rerror_rate', u'label'],\n",
      "      dtype='object')\n",
      "----Making Prediction for Input--------\n",
      "[1 'tcp' 'smtp' 'SF' 2599 293 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 3 3 0.0 0.0\n",
      " 0.0 0.0 1.0 0.0 0.0 255 203 0.8 0.13 0.0 0.0 0.0 0.0 0.19 0.0 'mailbomb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:47: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  ----DOS ---- | --- Probe ---- | ---- R2L ---- | ----U2R ---- | \n",
      "(array([[0.6204785]], dtype=float32), array([[0.32257918]], dtype=float32), array([[0.21764824]], dtype=float32), array([[0.14408399]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "#(Normal 5) , rootkit - 9128 sqlattack -> 8125 \n",
    "#Working Proper 153 (Mailbomb --> DOS)  292 (mscan -> Probe , U2R)  925 --> Buffer OVerflow (U2R)\n",
    "newdf_test_instance=testing(153,model_dos,model_probe,model_r2l,model_u2r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2057
    },
    "colab_type": "code",
    "id": "5_Akan38fzAD",
    "outputId": "b725a0f1-85a0-4e1a-ea9b-047dc87f8c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 122)               15006     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 366)               45018     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 366)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 60)                22020     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 82,105\n",
      "Trainable params: 82,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "113270/113270 [==============================] - 32s 285us/step - loss: 0.1497 - acc: 0.9869\n",
      "Epoch 2/2\n",
      "113270/113270 [==============================] - 31s 278us/step - loss: 0.0788 - acc: 0.9895\n",
      "17171/17171 [==============================] - 2s 107us/step\n",
      "------Evaluating Accuracy on DOS--------\n",
      "acc: 86.97%\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 122)               15006     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 366)               45018     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 366)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 60)                22020     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 82,105\n",
      "Trainable params: 82,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "113270/113270 [==============================] - 32s 286us/step - loss: 0.1518 - acc: 0.9872\n",
      "Epoch 2/2\n",
      "113270/113270 [==============================] - 33s 287us/step - loss: 0.0795 - acc: 0.9900\n",
      "17171/17171 [==============================] - 2s 110us/step\n",
      "------Evaluating Accuracy on R2L--------\n",
      "acc: 87.51%\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 122)               15006     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 366)               45018     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 366)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 60)                22020     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 82,105\n",
      "Trainable params: 82,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "113270/113270 [==============================] - 34s 301us/step - loss: 0.1477 - acc: 0.9873\n",
      "Epoch 2/2\n",
      "113270/113270 [==============================] - 33s 288us/step - loss: 0.0790 - acc: 0.9899\n",
      "17171/17171 [==============================] - 2s 114us/step\n",
      "------Evaluating Accuracy on Probe--------\n",
      "acc: 87.84%\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 122)               15006     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 366)               45018     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 366)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 60)                22020     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 82,105\n",
      "Trainable params: 82,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "113270/113270 [==============================] - 35s 305us/step - loss: 0.1546 - acc: 0.9876\n",
      "Epoch 2/2\n",
      "113270/113270 [==============================] - 33s 292us/step - loss: 0.0786 - acc: 0.9898\n",
      "17171/17171 [==============================] - 2s 114us/step\n",
      "------Evaluating Accuracy on U2R--------\n",
      "acc: 86.59%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_dos=create_network()\n",
    "model_dos.fit(X_DoS,Y_DoS,epochs=2,batch_size=10)\n",
    "score_model_dos = model_dos.evaluate(X_DoS_test, Y_DoS_test,batch_size=10)\n",
    "print(\"------Evaluating Accuracy on DOS--------\")\n",
    "print(\"%s: %.2f%%\" % (model_dos.metrics_names[1], score_model_dos[1]*100))\n",
    "model_dos_json = model_dos.to_json()\n",
    "with open(\"model_dos.json\", \"w\") as json_file:\n",
    "    json_file.write(model_dos_json)\n",
    "# serialize weights to HDF5\n",
    "model_dos.save_weights(\"model_dos.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "model_r2l=create_network()\n",
    "model_r2l.fit(X_DoS,Y_DoS,epochs=2,batch_size=10)\n",
    "score_model_r2l = model_r2l.evaluate(X_DoS_test, Y_DoS_test,batch_size=10)\n",
    "print(\"------Evaluating Accuracy on R2L--------\")\n",
    "print(\"%s: %.2f%%\" % (model_r2l.metrics_names[1], score_model_r2l[1]*100))\n",
    "model_r2l_json = model_r2l.to_json()\n",
    "with open(\"model_r2l.json\", \"w\") as json_file:\n",
    "    json_file.write(model_r2l_json)\n",
    "# serialize weights to HDF5\n",
    "model_r2l.save_weights(\"model_r2l.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "model_probe=create_network()\n",
    "model_probe.fit(X_DoS,Y_DoS,epochs=2,batch_size=10)\n",
    "score_model_probe = model_probe.evaluate(X_DoS_test, Y_DoS_test,batch_size=10)\n",
    "print(\"------Evaluating Accuracy on Probe--------\")\n",
    "print(\"%s: %.2f%%\" % (model_probe.metrics_names[1], score_model_probe[1]*100))\n",
    "model_probe_json = model_probe.to_json()\n",
    "with open(\"model_probe.json\", \"w\") as json_file:\n",
    "    json_file.write(model_probe_json)\n",
    "# serialize weights to HDF5\n",
    "model_probe.save_weights(\"model_probe.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "model_u2r=create_network()\n",
    "model_u2r.fit(X_DoS,Y_DoS,epochs=2,batch_size=10)\n",
    "score_model_u2r = model_u2r.evaluate(X_DoS_test, Y_DoS_test,batch_size=10)\n",
    "print(\"------Evaluating Accuracy on U2R--------\")\n",
    "print(\"%s: %.2f%%\" % (model_u2r.metrics_names[1], score_model_u2r[1]*100))\n",
    "model_u2r_json = model_u2r.to_json()\n",
    "with open(\"model_u2r.json\", \"w\") as json_file:\n",
    "    json_file.write(model_u2r_json)\n",
    "# serialize weights to HDF5\n",
    "model_u2r.save_weights(\"model_u2r.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5szKaMzgQ74"
   },
   "source": [
    "### Evaluate Predictions on Subset of Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1989
    },
    "colab_type": "code",
    "id": "r3zV3b0GgQGV",
    "outputId": "af28ed4e-2c87-4bdb-c070-8e7da7bc5ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 26)                364       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 135       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "113270/113270 [==============================] - 22s 195us/step - loss: 0.1899 - acc: 0.9783\n",
      "Epoch 2/2\n",
      "113270/113270 [==============================] - 21s 184us/step - loss: 0.1161 - acc: 0.9836\n",
      "113270/113270 [==============================] - 10s 92us/step\n",
      "----Evaluating DOS Accuracy on Small Features-----\n",
      "acc: 98.94%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 26)                364       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 5)                 135       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "78999/78999 [==============================] - 16s 200us/step - loss: -1.4112 - acc: 0.8207\n",
      "Epoch 2/2\n",
      "78999/78999 [==============================] - 15s 184us/step - loss: -1.7244 - acc: 0.8290\n",
      "78999/78999 [==============================] - 8s 97us/step\n",
      "----Evaluating Probe Accuracy on Small Features-----\n",
      "acc: 84.33%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 26)                364       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 135       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "68338/68338 [==============================] - 15s 213us/step - loss: 0.1730 - acc: 0.9736\n",
      "Epoch 2/2\n",
      "68338/68338 [==============================] - 13s 193us/step - loss: 0.0669 - acc: 0.9651\n",
      "68338/68338 [==============================] - 7s 101us/step\n",
      "----Evaluating R2L Accuracy on Small Features-----\n",
      "acc: 96.54%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 26)                364       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 5)                 135       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "67395/67395 [==============================] - 15s 216us/step - loss: 0.1207 - acc: 0.9942\n",
      "Epoch 2/2\n",
      "67395/67395 [==============================] - 13s 199us/step - loss: 0.0260 - acc: 0.9992\n",
      "67395/67395 [==============================] - 7s 104us/step\n",
      "----Evaluating U2R Accuracy on Small Features-----\n",
      "acc: 99.92%\n"
     ]
    }
   ],
   "source": [
    "def create_network_reduced():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,),kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(26,activation='relu',kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(5,activation='relu',kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "model_dos_small=create_network_reduced()\n",
    "model_dos_small.fit(X_rfeDoS,Y_DoS,epochs=2,batch_size=10)\n",
    "score_model_dos_small = model_dos_small.evaluate(X_rfeDoS, Y_DoS,batch_size=10)\n",
    "print(\"----Evaluating DOS Accuracy on Small Features-----\")\n",
    "print(\"%s: %.2f%%\" % (model_dos_small.metrics_names[1], score_model_dos_small[1]*100))\n",
    "model_probe_small=create_network_reduced()\n",
    "model_probe_small.fit(X_rfeProbe,Y_Probe,epochs=2,batch_size=10)\n",
    "score_model_probe_small = model_probe_small.evaluate(X_rfeProbe, Y_Probe,batch_size=10)\n",
    "print(\"----Evaluating Probe Accuracy on Small Features-----\")\n",
    "print(\"%s: %.2f%%\" % (model_probe_small.metrics_names[1], score_model_probe_small[1]*100))\n",
    "model_r2l_small=create_network_reduced()\n",
    "model_r2l_small.fit(X_rfeR2L,Y_R2L,epochs=2,batch_size=10)\n",
    "score_model_r2l_small = model_r2l_small.evaluate(X_rfeR2L, Y_R2L,batch_size=10)\n",
    "print(\"----Evaluating R2L Accuracy on Small Features-----\")\n",
    "print(\"%s: %.2f%%\" % (model_r2l_small.metrics_names[1], score_model_r2l_small[1]*100))\n",
    "model_u2r_small=create_network_reduced()\n",
    "model_u2r_small.fit(X_rfeU2R,Y_U2R,epochs=2,batch_size=10)\n",
    "score_model_u2r_small = model_u2r_small.evaluate(X_rfeU2R, Y_U2R,batch_size=10)\n",
    "print(\"----Evaluating U2R Accuracy on Small Features-----\")\n",
    "print(\"%s: %.2f%%\" % (model_u2r_small.metrics_names[1], score_model_u2r_small[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nids.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
